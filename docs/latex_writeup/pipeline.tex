\documentclass[12pt,preprint]{aastex}

% has to be before amssymb it seems
\usepackage{color,hyperref}
\definecolor{linkcolor}{rgb}{0,0,0.5}
\hypersetup{colorlinks=true,linkcolor=linkcolor,citecolor=linkcolor,
            filecolor=linkcolor,urlcolor=linkcolor}

\usepackage{url}
\usepackage{algorithmic,algorithm}
\usepackage{amssymb,amsmath}

\newcommand{\arxiv}[1]{\href{http://arxiv.org/abs/#1}{arXiv:#1}}

\usepackage{listings}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{language=Python,
        basicstyle=\footnotesize\ttfamily,
        showspaces=false,
        showstringspaces=false,
        tabsize=2,
        breaklines=false,
        breakatwhitespace=true,
        identifierstyle=\ttfamily,
        keywordstyle=\bfseries\color[rgb]{0.133,0.545,0.133},
        commentstyle=\color[rgb]{0.133,0.545,0.133},
        stringstyle=\color[rgb]{0.627,0.126,0.941},
    }

\newcommand{\project}[1]{{\sffamily #1}}
\newcommand{\Python}{\project{Python}}
\newcommand{\numpy}{\project{numpy}}
\newcommand{\github}{\project{GitHub}}
\newcommand{\pip}{\project{pip}}
\newcommand{\thisplain}{pipeline}
\newcommand{\this}{\project{\thisplain}}
\newcommand{\paper}{document}
\newcommand{\license}{GNU General Public License v3}

\newcommand{\foreign}[1]{\emph{#1}}
\newcommand{\etal}{\foreign{et\,al.}}
\newcommand{\etc}{\foreign{etc.}}

\newcommand{\Fig}[1]{Figure~\ref{fig:#1}}
\newcommand{\fig}[1]{\Fig{#1}}
\newcommand{\figlabel}[1]{\label{fig:#1}}
\newcommand{\Tab}[1]{Table~\ref{tab:#1}}
\newcommand{\tab}[1]{\Tab{#1}}
\newcommand{\tablabel}[1]{\label{tab:#1}}
\newcommand{\Eq}[1]{Equation~(\ref{eq:#1})}
\newcommand{\eq}[1]{\Eq{#1}}
\newcommand{\eqlabel}[1]{\label{eq:#1}}
\newcommand{\Sect}[1]{Section~\ref{sect:#1}}
\newcommand{\sect}[1]{\Sect{#1}}
\newcommand{\App}[1]{Appendix~\ref{sect:#1}}
\newcommand{\app}[1]{\App{#1}}
\newcommand{\sectlabel}[1]{\label{sect:#1}}
\newcommand{\Algo}[1]{Algorithm~\ref{algo:#1}}
\newcommand{\algo}[1]{\Algo{#1}}
\newcommand{\algolabel}[1]{\label{algo:#1}}

% math symbols
\newcommand{\dd}{\mathrm{d}}
\newcommand{\like}{\mathscr{L}}
\newcommand{\bvec}[1]{\boldsymbol{#1}}
\newcommand{\paramvector}[1]{\bvec{#1}}
\newcommand{\normal}[2]{\mathcal{N} (#1, #2)}
\newcommand{\ensemble}{S}
\newcommand{\colorens}[1]{\ensemble^{(#1)}}
\newcommand{\red}{\colorens{0}}
\newcommand{\blue}{\colorens{1}}
\renewcommand{\vector}[1]{#1}
\renewcommand{\matrix}[1]{#1}
\newcommand{\pr}[1]{\ensuremath{p(#1)}}
\newcommand{\af}{\ensuremath{a_f}}
\newcommand{\expect}[1]{\left<#1\right>}

% model parameters
\newcommand{\model}{\ensuremath{\vector{\Theta}}}
\newcommand{\data}{\ensuremath{\vector{D}}}
\newcommand{\nuisance}{\ensuremath{\vector{\alpha}}}
\newcommand{\link}{\ensuremath{X}}

% units
\newcommand{\unit}[1]{\mathrm{#1}}

% quotes!
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}

% Citation alias
% TODO - \defcitealias{Letey:2018}{LW18}

\begin{document}

\title{\this: TODO}

\newcommand{\cu}{1}
\author{John~Letey\altaffilmark{\cu},
    Tony~E.~Wong\altaffilmark{\cu}}
\altaffiltext{\cu}{University of Colorado at Boulder}

\begin{abstract}
    TODO!!!  The code is available online
    at \url{http://mussles.github.io/\thisplain/} under the \license.
\end{abstract}

\keywords{
    methods: statistical ---
    methods: Markov chain Monte Carlo ---
    TODO
}

~\clearpage

\noindent
\emph{Note: If you want to get started immediately with the \this\ package,
  start at \app{install} on
  page~\pageref{sect:install} or visit the online documentation at
  \url{https://mussles.github.io/pipeline}. If you are sampling with \this\ and having
  low-acceptance-rate or other issues, there is some advice in
  \sect{advice} starting on page~\pageref{sect:advice}.}

\section{Introduction}

Throughout previous years of development, Markov chain Monte Carlo (MCMC) has evolved from a foregone algorithm to a more general way to fit real-life data.

\section{The Algorithm}\sectlabel{algo}

One of the most commonly used MCMC algorithms is the Adaptive Metropolis-Hastings Algorithm, proposed by Haario, et al. in their \emph{An Adaptive Metropolis Algorithm} \cite{haario2001}. In their paper, they propose an algorithm that streamlines the task of setting the step-size, compared to the arduous process outlined in the original algorithm. The original algorithm was introduced by Metropolis and Hastings, respectively, in their separate papers \cite{metropolis1953} and \cite{hastings1970}. The algorithm that does TODO, was originally proposed by Metropolis, and was further refined by Hastings to include TODO. Contained in the following algorithms, is rough pseudo-code for both the Metropolis-Hastings algorithm and also the Adaptive Metropolis-Hastings Algorithm:

\begin{algorithm}
\caption{The Metropolis-Hastings algorithm}
\label{alg:mh}
\begin{algorithmic}[1]

  \STATE Draw $X^0\sim\mu$ where $\mu$ is the initial condition.
  \STATE Set $t\leftarrow0$.
  \REPEAT
    \STATE Draw $Y^t\sim q(y^t|x^t)$.
    \STATE Compute $\alpha = \min\left\{
      \frac{\pi(y^t)}{\pi(x^t)}\frac{q(x^t|y^t)}{q(y^t|x^t)}, 1\right\}$
    \STATE Draw $U\sim\mathcal{U}[0,1]$.
    \IF{$U\le\alpha$}
      \STATE Set $X^{t+1}\leftarrow Y^t$.
    \ELSE
      \STATE Set $X^{t+1}\leftarrow X^t$.
    \ENDIF
    \STATE Set $t\leftarrow t+1$.
  \UNTIL{Sufficiently many samples have been produced.}

\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Adaptive Metropolis-Hastings algorithm}
\label{alg:adaptive_mh}
\begin{algorithmic}
  \STATE Draw $X^0\sim\mu$ where $\mu$ is the initial condition.
  \STATE Set $\theta^0$ to an arbitrary valid value.
  \STATE Set $t\leftarrow0$.
  \REPEAT
      \STATE Compute $\theta^t = \gamma^t(\theta^0,X^0,\dots,X^{t-1})$ where
      $\gamma^t$ is a transformation that update the parameters based on past
      samples.
      \STATE Draw $X^{t + 1}$ using the proposal $q(\cdot|x^t,\theta^t)$ with
      the Metropolis-Hastings rule.
      \STATE Set $t\leftarrow t+1$.
  \UNTIL{The accept rate of the last $K$ iterations are close to $0.234$.}
  \STATE Set $\theta\leftarrow\theta^t$.
  \STATE Perform Algorithm~\ref{alg:mh} with proposal $q(\cdot|x) =
  q(\cdot|x,\theta)$.
\end{algorithmic}
\end{algorithm}

\section{Discussion \& Tips}\sectlabel{advice}

\begin{thebibliography}{}\raggedright
\bibitem[Haario, et al.(2001)]{haario2001}
    Haario, H.; Saksman, E.; Tamminen, J. (2001). "An adaptive Metropolis algorithm." Bernoulli, 7(2): 223–242.
\bibitem[Metropolis, et al.(1953)]{metropolis1953}
    Metropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A., and Teller, E. (1953). "Equations of state calculations by fast computing machines." J. Chem. Phys., 21(6): 1087–1092.
\bibitem[Hastings(1970)]{hastings1970}
    Hastings, W. (1970). "Monte Carlo sampling methods using Markov chains and their application." Biometrika, 57: 97–109.
\end{thebibliography}

\clearpage
\appendix
\section{Installation}\sectlabel{install}

\section{Issues \& Contributions}

The development of \this\ is being coordinated on \github\ at
\url{http://github.com/mussles/pipeline} and contributions are welcome. If you
encounter any problems with the code, please report them at
\url{http://github.com/mussles/pipeline/issues} and consider
contributing a patch.

\section{Online Documentation}

To learn more about how to use \this\ in practice, it is best to check out the
documentation on the website \url{https://mussles.github.io/pipeline}. This page includes
the API documentation and many examples of possible work flows.

\end{document}
